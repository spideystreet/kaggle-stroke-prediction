{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import jinja2\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Add the project root directory to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added '{project_root}' to sys.path\")\n",
    "\n",
    "import src.load_libs \n",
    "from src.load_data import load_stroke_data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Attempting to load file: healthcare-dataset-stroke-data.csv from dataset fedesoriano/stroke-prediction-dataset\n",
      "Dataset loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "df = load_stroke_data()\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5110, 12)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "ever_married           0\n",
       "work_type              0\n",
       "Residence_type         0\n",
       "avg_glucose_level      0\n",
       "bmi                  201\n",
       "smoking_status         0\n",
       "stroke                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mmm... empty datas on bmi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do median imputation for bmi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing BMI values before imputation: 201\n",
      "Median BMI: 28.10\n",
      "Missing BMI values after imputation: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/w9p124nd6jb9srzf94f0v2q80000gn/T/ipykernel_81543/1255845138.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['bmi'].fillna(median_bmi, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    # Check missing values before imputation\n",
    "    print(\"Missing BMI values before imputation:\", df['bmi'].isnull().sum())\n",
    "\n",
    "    if df['bmi'].isnull().sum() > 0:\n",
    "        # Calculate the median BMI (ignoring NaNs)\n",
    "        median_bmi = df['bmi'].median()\n",
    "        print(f\"Median BMI: {median_bmi:.2f}\")\n",
    "\n",
    "        # Impute missing values using the median\n",
    "        # This is the core line for imputation:\n",
    "        df['bmi'].fillna(median_bmi, inplace=True)\n",
    "\n",
    "        # Verify that missing values have been filled\n",
    "        print(\"Missing BMI values after imputation:\", df['bmi'].isnull().sum())\n",
    "    else:\n",
    "        print(\"No missing BMI values found.\")\n",
    "else:\n",
    "    print(\"DataFrame 'df' not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/w9p124nd6jb9srzf94f0v2q80000gn/T/ipykernel_81543/2968852825.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['bmi'].fillna(median_bmi, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "median_bmi = df['bmi'].median()\n",
    "df['bmi'].fillna(median_bmi, inplace=True)\n",
    "\n",
    "# Drop ID\n",
    "if 'id' in df.columns:\n",
    "    df.drop('id', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               0\n",
       "age                  0\n",
       "hypertension         0\n",
       "heart_disease        0\n",
       "ever_married         0\n",
       "work_type            0\n",
       "Residence_type       0\n",
       "avg_glucose_level    0\n",
       "bmi                  0\n",
       "smoking_status       0\n",
       "stroke               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML algos need numerical features, so we need to convert the categorical features to numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape before encoding: (5110, 11)\n",
      "Columns before encoding: ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status', 'stroke']\n",
      "\n",
      "Data types before encoding:\n",
      "gender                object\n",
      "age                  float64\n",
      "hypertension           int64\n",
      "heart_disease          int64\n",
      "ever_married          object\n",
      "work_type             object\n",
      "Residence_type        object\n",
      "avg_glucose_level    float64\n",
      "bmi                  float64\n",
      "smoking_status        object\n",
      "stroke                 int64\n",
      "dtype: object\n",
      "Initial preprocessing done.\n",
      "Columns: ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'stroke', 'gender_Male', 'gender_Other', 'ever_married_Yes', 'work_type_Never_worked', 'work_type_Private', 'work_type_Self-employed', 'work_type_children', 'Residence_type_Urban', 'smoking_status_formerly smoked', 'smoking_status_never smoked', 'smoking_status_smokes']\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    print(\"DataFrame shape before encoding:\", df.shape)\n",
    "    print(\"Columns before encoding:\", df.columns.tolist())\n",
    "    print(\"\\nData types before encoding:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    # Identify categorical columns to encode (excluding binary 0/1 already numerical)\n",
    "    # We'll encode 'object' type columns. We can also explicitly list them.\n",
    "    categorical_to_encode = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    df_processed = pd.get_dummies(df, columns=categorical_to_encode, drop_first=True, dtype=int)\n",
    "    print(\"Initial preprocessing done.\")\n",
    "    print(\"Columns:\", df_processed.columns.tolist())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gonna split here our dataset into training and testing dataset.  (BEFORE the scaling and standardization)  \n",
    "We will use 80% of the dataset for training and 20% for testing, good for this case i guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train and test sets...\n",
      "Train shape: (4088, 16) Test shape: (1022, 16)\n"
     ]
    }
   ],
   "source": [
    "# --- Define Features (X) and Target (y) ---\n",
    "# Ensure 'stroke' column exists\n",
    "if 'stroke' not in df_processed.columns:\n",
    "    raise ValueError(\"'stroke' column not found in the DataFrame after preprocessing.\")\n",
    "\n",
    "X = df_processed.drop('stroke', axis=1)\n",
    "y = df_processed['stroke']\n",
    "\n",
    "# --- Split Data ---\n",
    "print(\"Splitting data into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to scale our features, ML perform better when numerical features are scaled.  \n",
    "For example, age, avg_glucole_lvl, bmi ae on very different ranges, so we need to scale them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we will use standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling numerical columns: ['age', 'avg_glucose_level', 'bmi', 'hypertension', 'heart_disease']\n",
      "Scaling complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Scale Numerical Features (AFTER SPLIT) ---\n",
    "# Identify numerical columns (excluding potentially added binary encoded ones)\n",
    "# Adjust this list based on your actual columns after encoding\n",
    "numerical_cols = ['age', 'avg_glucose_level', 'bmi', 'hypertension', 'heart_disease'] # Example list\n",
    "# Ensure columns exist\n",
    "numerical_cols = [col for col in numerical_cols if col in X_train.columns]\n",
    "print(f\"Scaling numerical columns: {numerical_cols}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Fit scaler ONLY on training data\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "# Transform test data using the SAME fitted scaler\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "print(\"Scaling complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our datas are cleaned, encoded and scaled, we can save them to a new file before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved successfully to: ../data/processed/stroke_data_processed.csv\n",
      "Final DataFrame shape: (5110, 17)\n",
      "Columns in saved data: ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'stroke', 'gender_Male', 'gender_Other', 'ever_married_Yes', 'work_type_Never_worked', 'work_type_Private', 'work_type_Self-employed', 'work_type_children', 'Residence_type_Urban', 'smoking_status_formerly smoked', 'smoking_status_never smoked', 'smoking_status_smokes']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# index=False prevents pandas from writing the DataFrame index as a column\n",
    "processed_file_path = '../data/processed/stroke_data_processed.csv'\n",
    "df_processed.to_csv(processed_file_path, index=False)\n",
    "\n",
    "print(f\"Processed data saved successfully to: {processed_file_path}\")\n",
    "print(f\"Final DataFrame shape: {df_processed.shape}\")\n",
    "print(\"Columns in saved data:\", df_processed.columns.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
